{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from util_functions import process_files\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate fixed at 0.0001, dropout: 0.25\n",
      "\n",
      "Train on 1306 samples, validate on 146 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.6723 - acc: 0.7619 - val_loss: 0.8495 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5673 - acc: 0.7741 - val_loss: 1.4704 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.5357 - acc: 0.7741 - val_loss: 1.4306 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.5351 - acc: 0.7741 - val_loss: 1.3604 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.5359 - acc: 0.7741 - val_loss: 1.4911 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.5326 - acc: 0.7741 - val_loss: 1.4340 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.5310 - acc: 0.7741 - val_loss: 1.4050 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.5286 - acc: 0.7741 - val_loss: 1.3791 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.5228 - acc: 0.7741 - val_loss: 1.5455 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.5117 - acc: 0.7741 - val_loss: 1.4201 - val_acc: 0.0068\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.4987 - acc: 0.7772 - val_loss: 1.3729 - val_acc: 0.0479\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4762 - acc: 0.7956 - val_loss: 1.5714 - val_acc: 0.0959\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4611 - acc: 0.8078 - val_loss: 1.1281 - val_acc: 0.2945\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.4453 - acc: 0.8178 - val_loss: 1.5550 - val_acc: 0.2397\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.4345 - acc: 0.8155 - val_loss: 1.3164 - val_acc: 0.3082\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.4200 - acc: 0.8224 - val_loss: 1.4735 - val_acc: 0.3082\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.4190 - acc: 0.8170 - val_loss: 1.0446 - val_acc: 0.4178\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4174 - acc: 0.8247 - val_loss: 1.0308 - val_acc: 0.4178\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4096 - acc: 0.8239 - val_loss: 1.0495 - val_acc: 0.4315\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.4032 - acc: 0.8308 - val_loss: 1.2047 - val_acc: 0.4178\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.4002 - acc: 0.8300 - val_loss: 1.0566 - val_acc: 0.4521\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.3939 - acc: 0.8315 - val_loss: 1.1240 - val_acc: 0.4521\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.4015 - acc: 0.8270 - val_loss: 1.2513 - val_acc: 0.4247\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3914 - acc: 0.8361 - val_loss: 1.3179 - val_acc: 0.4247\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3906 - acc: 0.8377 - val_loss: 1.0085 - val_acc: 0.4658\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3878 - acc: 0.8338 - val_loss: 1.2819 - val_acc: 0.4452\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.3862 - acc: 0.8346 - val_loss: 0.8495 - val_acc: 0.5068\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.3870 - acc: 0.8331 - val_loss: 0.9025 - val_acc: 0.5068\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.3830 - acc: 0.8407 - val_loss: 1.0229 - val_acc: 0.4932\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.3809 - acc: 0.8400 - val_loss: 1.1402 - val_acc: 0.4726\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.3743 - acc: 0.8423 - val_loss: 1.2225 - val_acc: 0.4726\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.3720 - acc: 0.8438 - val_loss: 1.1197 - val_acc: 0.5068\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.3736 - acc: 0.8423 - val_loss: 1.0402 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.3721 - acc: 0.8346 - val_loss: 0.7504 - val_acc: 0.5274\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.3694 - acc: 0.8461 - val_loss: 1.1263 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.3712 - acc: 0.8361 - val_loss: 0.9142 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.3721 - acc: 0.8423 - val_loss: 0.7566 - val_acc: 0.5137\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.3654 - acc: 0.8438 - val_loss: 1.1361 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.3643 - acc: 0.8361 - val_loss: 0.8863 - val_acc: 0.5137\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.3633 - acc: 0.8354 - val_loss: 1.2974 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.3640 - acc: 0.8438 - val_loss: 1.0354 - val_acc: 0.5274\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.3601 - acc: 0.8430 - val_loss: 0.9998 - val_acc: 0.5137\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.3576 - acc: 0.8384 - val_loss: 1.2251 - val_acc: 0.5068\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.3582 - acc: 0.8430 - val_loss: 0.9259 - val_acc: 0.5274\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.3573 - acc: 0.8446 - val_loss: 1.0132 - val_acc: 0.5479\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.3609 - acc: 0.8400 - val_loss: 0.8672 - val_acc: 0.5342\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.3547 - acc: 0.8438 - val_loss: 1.1950 - val_acc: 0.5274\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.3531 - acc: 0.8469 - val_loss: 1.2485 - val_acc: 0.5068\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.3581 - acc: 0.8415 - val_loss: 1.1107 - val_acc: 0.5274\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.3474 - acc: 0.8438 - val_loss: 0.8481 - val_acc: 0.5753\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.3522 - acc: 0.8423 - val_loss: 0.7681 - val_acc: 0.5890\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.3507 - acc: 0.8423 - val_loss: 1.2315 - val_acc: 0.5479\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.3500 - acc: 0.8415 - val_loss: 1.1443 - val_acc: 0.5685\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.3477 - acc: 0.8392 - val_loss: 1.0157 - val_acc: 0.5890\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.3503 - acc: 0.8469 - val_loss: 1.2692 - val_acc: 0.5479\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.3469 - acc: 0.8453 - val_loss: 0.8760 - val_acc: 0.5890\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.3449 - acc: 0.8453 - val_loss: 1.0070 - val_acc: 0.5959\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.3472 - acc: 0.8469 - val_loss: 0.7897 - val_acc: 0.5959\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.3453 - acc: 0.8461 - val_loss: 1.0506 - val_acc: 0.5890\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.3426 - acc: 0.8476 - val_loss: 1.0032 - val_acc: 0.5890\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.3407 - acc: 0.8469 - val_loss: 1.1713 - val_acc: 0.5890\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.3401 - acc: 0.8492 - val_loss: 1.2077 - val_acc: 0.5890\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.3406 - acc: 0.8484 - val_loss: 1.2667 - val_acc: 0.5753\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.3411 - acc: 0.8484 - val_loss: 1.1407 - val_acc: 0.6027\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.3355 - acc: 0.8553 - val_loss: 1.0330 - val_acc: 0.6096\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.3404 - acc: 0.8507 - val_loss: 1.2035 - val_acc: 0.6027\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.3342 - acc: 0.8606 - val_loss: 1.0852 - val_acc: 0.6096\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.3410 - acc: 0.8476 - val_loss: 0.9688 - val_acc: 0.5959\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.3346 - acc: 0.8476 - val_loss: 1.1656 - val_acc: 0.5959\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.3385 - acc: 0.8499 - val_loss: 1.0681 - val_acc: 0.5959\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.3380 - acc: 0.8515 - val_loss: 1.2870 - val_acc: 0.5822\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.3365 - acc: 0.8484 - val_loss: 1.1568 - val_acc: 0.6096\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.3322 - acc: 0.8515 - val_loss: 1.1585 - val_acc: 0.6096\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.3353 - acc: 0.8583 - val_loss: 1.1024 - val_acc: 0.5959\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.3344 - acc: 0.8476 - val_loss: 1.1435 - val_acc: 0.6096\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.3305 - acc: 0.8568 - val_loss: 1.1251 - val_acc: 0.5959\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.3322 - acc: 0.8476 - val_loss: 1.3870 - val_acc: 0.5822\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.3336 - acc: 0.8545 - val_loss: 1.2282 - val_acc: 0.6096\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.3288 - acc: 0.8568 - val_loss: 1.0482 - val_acc: 0.6096\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.3292 - acc: 0.8492 - val_loss: 1.1507 - val_acc: 0.6096\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.3289 - acc: 0.8515 - val_loss: 1.0169 - val_acc: 0.6096\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.3291 - acc: 0.8515 - val_loss: 0.9447 - val_acc: 0.6164\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8545 - val_loss: 1.2899 - val_acc: 0.6027\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.3285 - acc: 0.8560 - val_loss: 1.1599 - val_acc: 0.6164\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.3277 - acc: 0.8545 - val_loss: 1.2087 - val_acc: 0.6164\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.3299 - acc: 0.8568 - val_loss: 1.2204 - val_acc: 0.6164\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.3221 - acc: 0.8614 - val_loss: 1.1455 - val_acc: 0.6164\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.3199 - acc: 0.8576 - val_loss: 1.1059 - val_acc: 0.6164\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.3263 - acc: 0.8622 - val_loss: 0.8881 - val_acc: 0.6164\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.3252 - acc: 0.8568 - val_loss: 1.2346 - val_acc: 0.6164\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.3284 - acc: 0.8560 - val_loss: 1.3220 - val_acc: 0.5890\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.3225 - acc: 0.8583 - val_loss: 0.8008 - val_acc: 0.6096\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.3276 - acc: 0.8530 - val_loss: 0.8592 - val_acc: 0.5959\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.3304 - acc: 0.8591 - val_loss: 1.1143 - val_acc: 0.6164\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.3243 - acc: 0.8629 - val_loss: 1.0296 - val_acc: 0.6233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      " - 1s - loss: 0.3159 - acc: 0.8652 - val_loss: 1.2151 - val_acc: 0.6164\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.3240 - acc: 0.8476 - val_loss: 0.9040 - val_acc: 0.6233\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.3215 - acc: 0.8622 - val_loss: 1.0545 - val_acc: 0.6233\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.3191 - acc: 0.8691 - val_loss: 1.0729 - val_acc: 0.6164\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.3234 - acc: 0.8576 - val_loss: 1.1874 - val_acc: 0.6164\n",
      "Test loss: 0.58175981561274\n",
      "Test accuracy: 0.8024263431542461\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "\n",
    "# load the data\n",
    "x_train, y_train, f_train = process_files(\n",
    "                                    dataset='training', \n",
    "                                    features=['Mel'], \n",
    "                                    shape='flat')\n",
    "\n",
    "x_test, y_test, f_test = process_files(\n",
    "                                    dataset='test', \n",
    "                                    features=['Mel'], \n",
    "                                    shape='flat')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "#normalise\n",
    "x_train = x_train - x_train.mean()\n",
    "x_test = x_test - x_test.mean()\n",
    "x_train = x_train/LA.norm(x_train)\n",
    "x_test = x_test/LA.norm(x_test)\n",
    "\n",
    "# input image dimensions\n",
    "input_d = x_train.shape[1] #Depth\n",
    "input_h = x_train.shape[2] #Height\n",
    "input_w = x_train.shape[3] #Width\n",
    "\n",
    "#Reshaping to feed to network\n",
    "x_train = x_train.reshape(x_train.shape[0], input_h, input_w, input_d)\n",
    "x_test = x_test.reshape(x_test.shape[0], input_h, input_w, input_d)\n",
    "input_shape = (input_h, input_w, input_d)\n",
    "\n",
    "#Making them floats for TF\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# iterate over different hyperparameters to finetune them\n",
    "# from the results in 10 epochs we can see that the other learning rates are just too big. \n",
    "# Hence only this one will be used\n",
    "learning_rate = 0.0001\n",
    "dropout_rates = [0.25]\n",
    "\n",
    "for dr in dropout_rates:\n",
    "\n",
    "    print('learning rate fixed at 0.0001, dropout: ' + str(dr) + '\\n')        \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(80, kernel_size=(57, 6),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(80, kernel_size=(1, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 7), strides=(8, 7)))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(dr))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=keras.optimizers.Nadam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=2,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[tbCallBack])\n",
    "              \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])        \n",
    "\n",
    "    print('----------------------------------------------------\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
