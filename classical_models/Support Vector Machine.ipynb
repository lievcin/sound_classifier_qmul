{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "from util_functions import process_files_to_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train = process_files_to_mfccs(dataset='training')\n",
    "df_test = process_files_to_mfccs(dataset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_svm(df_train,df_test,C,gamma):\n",
    "\n",
    "    clf = svm.SVC(C=C, gamma=gamma)\n",
    "    \n",
    "    X_train = df_train.iloc[:,0:df_train.shape[1]-1]\n",
    "    X_test = df_test.iloc[:,0:df_train.shape[1]-1]\n",
    "    y_train = df_train['Label']\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "     \n",
    "    pred_train_series = pd.Series(y_pred_train,index = df_train.index)\n",
    "    pred_group_train_series = pred_train_series.groupby(pred_train_series.index).mean()\n",
    "    pred_train_boolean = pred_group_train_series >=0.5\n",
    "    y_pred_train_last = pred_train_boolean*1\n",
    "\n",
    "    pred_test_series = pd.Series(y_pred_test,index = df_test.index)\n",
    "    pred_group_test_series = pred_test_series.groupby(pred_test_series.index).mean()\n",
    "    pred_test_boolean = pred_group_test_series >=0.5\n",
    "    y_pred_test_last= pred_test_boolean*1\n",
    "\n",
    "    y_train = df_train['Label']\n",
    "    y_train_last = y_train.groupby(y_train.index).mean()\n",
    "\n",
    "    y_test = df_test['Label']\n",
    "    y_test_last = y_test.groupby(y_test.index).mean()\n",
    "    \n",
    "    return y_train_last,y_pred_train_last,y_test_last,y_pred_test_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df_train,folds):\n",
    "    \n",
    "    C_range = np.logspace(-2, 10, 13)\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    results=np.empty((folds,len(C_range),len(gamma_range)))\n",
    "\n",
    "    X = np.unique(df_train.index.values)\n",
    "    np.random.shuffle(X)\n",
    "    kf = KFold(n_splits=3)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = df_train.loc[X[train_index]], df_train.loc[X[test_index]]\n",
    "        i,k = 0,0\n",
    "        for C in C_range:\n",
    "            j=0\n",
    "            for gamma in gamma_range:\n",
    "                y_train, y_pred_train, y_test, y_pred_test = classification_svm(X_train,X_test,C,gamma)\n",
    "                train_acc = calculate_accuracies(y_true=y_train, y_pred=y_pred_train)\n",
    "                test_acc = calculate_accuracies(y_true=y_test, y_pred=y_pred_test)\n",
    "                results[k,i,j]=test_acc\n",
    "                j+=1\n",
    "            i+=1\n",
    "        k+=1\n",
    "\n",
    "    average_acc = np.sum(results,axis=0)/folds\n",
    "    indexes_max = np.unravel_index(np.argmax(average_acc, axis=None), average_acc.shape)\n",
    "    best_C = C_range[indexes_max[0]]    \n",
    "    best_gamma = gamma_range[indexes_max[1]] \n",
    "        \n",
    "    return best_C, best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(y_true, y_pred):\n",
    "    return np.sum(np.array([y_true==y_pred]))/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report(y_true, y_pred, accuracy, dataset):    \n",
    "    print(dataset + ' Set:\\n')\n",
    "    print(dataset + ' Confusion Matrix:')\n",
    "    print(confusion_matrix(y_true, y_pred))    \n",
    "    print(dataset + ' Classification report:')\n",
    "    print(classification_report(y_true, y_pred))    \n",
    "    print(dataset + ' Accuracy: ' + str(accuracy))    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Set:\n",
      "\n",
      "Training Confusion Matrix:\n",
      "[[112   2]\n",
      " [  2  77]]\n",
      "Training Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       114\n",
      "          1       0.97      0.97      0.97        79\n",
      "\n",
      "avg / total       0.98      0.98      0.98       193\n",
      "\n",
      "Train Accuracy: 0.979274611399\n",
      "\n",
      "\n",
      "Test Set:\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[48  2]\n",
      " [10 24]]\n",
      "Test Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89        50\n",
      "          1       0.92      0.71      0.80        34\n",
      "\n",
      "avg / total       0.87      0.86      0.85        84\n",
      "\n",
      "Test Accuracy: 0.857142857143\n"
     ]
    }
   ],
   "source": [
    "#Classification with support vector machine using mfccs\n",
    "#We try finding the best C and gamma parameters to use\n",
    "C,gamma = cross_validate(df_train,folds=3)\n",
    "\n",
    "#Using the params found we run the model only on those\n",
    "y_train,y_train_pred, y_test, y_test_pred = classification_svm(df_train,df_test,c,gamma)\n",
    "\n",
    "#Calculate training and test accuracy for the model\n",
    "train_acc = calculate_accuracies(y_true=y_train, y_pred=y_pred_train)\n",
    "test_acc = calculate_accuracies(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "#Get report for model\n",
    "class_report(y_train, y_pred_train, train_acc, dataset='Training')\n",
    "class_report(y_test, y_pred_test, test_acc, dataset='Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
