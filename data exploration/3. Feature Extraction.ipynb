{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, audioread\n",
    "from util_functions import capture_class, random_shuffle, load_and_save_mel_data, load_and_save_mel_delta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_read_data(files_path, sr=16000): \n",
    "    audio, sample_rates, channels=[],[],[]\n",
    "    \n",
    "    # get all wav files in folder\n",
    "    sound_file_paths = glob.glob(files_path + '*.wav')\n",
    "    \n",
    "    #iterate over files and extract features.\n",
    "    for file in sound_file_paths:\n",
    "        ts, sr = librosa.load(file,sr=sr) #librosa returns a time series and sample rate\n",
    "        audio.append(ts)\n",
    "        sample_rates.append(sr)  \n",
    "        with audioread.audio_open(file) as input_file:\n",
    "            channels.append(input_file.channels)\n",
    "            \n",
    "    return audio, sample_rates, channels, sound_file_paths\n",
    "    \n",
    "def get_more_audio_features(audio, sr=16000):\n",
    "    frequencies, mel_deltas, mfccs, mfcc_deltas = [],[],[],[]    \n",
    "    \n",
    "    for a in audio:\n",
    "        # Get and store frequencies and their deltas\n",
    "        fr = librosa.feature.melspectrogram(y=a,sr=sr)\n",
    "        frequencies.append(fr)\n",
    "        mel_deltas.append(librosa.feature.delta(fr))\n",
    "        \n",
    "        # Get and store mfccs and their deltas        \n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(fr),sr=sr)\n",
    "        mfccs.append(mfcc)\n",
    "        mfcc_deltas.append(librosa.feature.delta(mfcc))\n",
    "\n",
    "    return frequencies, mel_deltas, mfccs, mfcc_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#path for audio files folder:\n",
    "raw_files_path = '../data/cats_dogs/'\n",
    "\n",
    "#call the function that will process the data.\n",
    "audio, sr, channels, file_names = load_and_read_data(raw_files_path)    \n",
    "\n",
    "#get additional features from audio\n",
    "frequencies, mel_deltas, mfccs, mfcc_deltas = get_more_audio_features(audio)\n",
    "\n",
    "\n",
    "#Combining the lists into a single dataframe\n",
    "#The result will be a row per file with several attributes.\n",
    "features_df = pd.DataFrame({'audio': audio,\n",
    "                            'sample_rates': sr,\n",
    "                            'channels': channels,\n",
    "                            'file_name': file_names,\n",
    "                            'Mel': frequencies,\n",
    "                            'Mel_deltas': mel_deltas,\n",
    "                            'mfccs': mfccs,\n",
    "                            'mfcc_deltas': mfcc_deltas,\n",
    "                            'File_id': [f.replace('../data/cats_dogs/', '').replace('.wav', '') for f in file_names]                            \n",
    "                           })\n",
    "\n",
    "#Adding the class label to the dataframe\n",
    "features_df['Label'] = features_df.apply(lambda row: capture_class(row['File_id']), axis=1)\n",
    "\n",
    "#We'll shuffle our dataframe for each class and split into training and test set\n",
    "training_df, test_df = random_shuffle(features_df, seed=1)\n",
    "\n",
    "#save as pickles\n",
    "training_df.to_pickle('../data_processed/'+ 'training_set.pkl')  \n",
    "test_df.to_pickle('../data_processed/'+ 'test_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the mels and MFCCs into numpy files for clustering.\n",
    "files_path = '../data/cats_dogs/'\n",
    "load_and_save_mel_data(files_path=files_path, sr=22050, dest_path='../data_processed/features_mel_spectrograms/')\n",
    "load_and_save_mel_delta_data(files_path=files_path, sr=22050, dest_path='../data_processed/features_delta_spectograms/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
